{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import read_experiment_results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df = read_experiment_results()\n",
    "\n",
    "# Calculate averages for each metric by model type\n",
    "avg_time_by_memory = results_df.groupby([\"model_type\", \"executor_memory_size\"])[\"total_time\"].mean().reset_index()\n",
    "avg_time_by_disk = results_df.groupby([\"model_type\", \"driver_memory_size\"])[\"total_time\"].mean().reset_index()\n",
    "avg_time_by_cores = (\n",
    "    results_df.groupby([\"model_type\", \"cores\"])[\"total_time\"].mean().reset_index()\n",
    "    if \"cores\" in results_df.columns\n",
    "    else None\n",
    ")\n",
    "\n",
    "avg_acc_by_memory = results_df.groupby([\"model_type\", \"executor_memory_size\"])[\"accuracy\"].mean().reset_index()\n",
    "avg_acc_by_disk = results_df.groupby([\"model_type\", \"driver_memory_size\"])[\"accuracy\"].mean().reset_index()\n",
    "avg_acc_by_cores = (\n",
    "    results_df.groupby([\"model_type\", \"cores\"])[\"accuracy\"].mean().reset_index()\n",
    "    if \"cores\" in results_df.columns\n",
    "    else None\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=300)\n",
    "\n",
    "\n",
    "def create_dual_axis_time_plot(ax, df, x_col, title):\n",
    "    logistic_data = df[df[\"model_type\"] == \"logistic\"]\n",
    "    gbt_data = df[df[\"model_type\"] == \"gbt\"]\n",
    "\n",
    "    # Left axis for logistic regression\n",
    "    color = \"tab:blue\"\n",
    "    ax.set_xlabel(x_col)\n",
    "    ax.set_ylabel(\"Logistic Time (ms)\", color=color)\n",
    "    ax.plot(logistic_data[x_col], logistic_data[\"total_time\"], \"o-\", color=color, label=\"Logistic\")\n",
    "    ax.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Right axis for GBT\n",
    "    ax2 = ax.twinx()\n",
    "    color = \"tab:red\"\n",
    "    ax2.set_ylabel(\"GBT Time (ms)\", color=color)\n",
    "    ax2.plot(gbt_data[x_col], gbt_data[\"total_time\"], \"o-\", color=color, label=\"GBT\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Add legend\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "create_dual_axis_time_plot(axes[0], avg_time_by_memory, \"executor_memory_size\", \"Training Time vs Executor Memory Size\")\n",
    "create_dual_axis_time_plot(axes[1], avg_time_by_disk, \"driver_memory_size\", \"Training Time vs Driver Memory Size\")\n",
    "\n",
    "if avg_time_by_cores is not None:\n",
    "    create_dual_axis_time_plot(axes[2], avg_time_by_cores, \"cores\", \"Training Time vs Number of Cores\")\n",
    "else:\n",
    "    axes[2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(\"plots/training_time.png\", dpi=600, bbox_inches=\"tight\", format=\"png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for all cases, the training time decreases with an increase of executor and driver memory size from 1g to 2g as well as from 1 to 2 cores. After that, however, the training time in general increases, although there are some variations.\n",
    "\n",
    "For logistic regression, the training time decreases between 1-4g executor memory, then increases between 4-6g, decreases between 6-10g, and then starts to increase again between 10-16g. For driver memory, it also decreases between 1-4g, then increases from 4-10g, and then decreases from 10-16g. For number of cores, it decreases from 1 to 2 cores, then increases with 3 cores, then decreases with 4 cores, and then steadily increases with 6 and 8 cores.\n",
    "\n",
    "For GBT, the pattern for executor memory is very similar to the one seen with logistic regression. For driver memory, it also decreases from 1-2g, but then increases from 2-4g and is almost the same at 4g as 6g, but then decreases between 6g-10g, and then increases again between 10g-16g (but by very little). For the number of cores, the training time also decreases from 1-2 cores, and almost the same at 3 cores as 2 cores, but then increases steadily from 3 to 8 cores, being at a longer training time level with 8 cores than with 1 core. That's interesting.\n",
    "\n",
    "In all cases, the training time is about 4.5 times longer with GBT than with logistic regression.\n",
    "\n",
    "Now, we have only tested memory ranges (both executor and driver memory) 1g-16g and numbers of cores 1-8, so making further experiments would maybe give some more insights.\n",
    "\n",
    "Of course, the decreases and increases are relatively small. The training time in all plots ranges from min 640ms to max 880ms for logistic regression, and from 3620ms to 3740ms for GBT.\n",
    "\n",
    "Consequently, changing these parameters seems to not have had much of an effect on training time, and it's difficult to draw any conclusions with regards to the scalability.\n",
    "\n",
    "It would also be interesting to see if the prediction quality has any connection to the experiment parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=300)\n",
    "\n",
    "\n",
    "def create_accuracy_plot(ax, df, x_col, title):\n",
    "    df = df.copy()\n",
    "\n",
    "    logistic_data = df[df[\"model_type\"] == \"logistic\"]\n",
    "    gbt_data = df[df[\"model_type\"] == \"gbt\"]\n",
    "\n",
    "    ax.plot(logistic_data[x_col], logistic_data[\"accuracy\"], \"o-\", color=\"tab:blue\", label=\"Logistic\")\n",
    "    ax.plot(gbt_data[x_col], gbt_data[\"accuracy\"], \"o-\", color=\"tab:red\", label=\"GBT\")\n",
    "\n",
    "    ax.set_xlabel(x_col)\n",
    "    ax.set_ylabel(\"Accuracy (%)\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    # Set y-axis to start from a reasonable minimum\n",
    "    y_min = max(df[\"accuracy\"].min() - 0.1, 0)\n",
    "    y_max = min(df[\"accuracy\"].max() + 0.1, 100)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "\n",
    "create_accuracy_plot(axes[0], avg_acc_by_memory, \"executor_memory_size\", \"Accuracy vs Memory Size\")\n",
    "create_accuracy_plot(axes[1], avg_acc_by_disk, \"driver_memory_size\", \"Accuracy vs Disk Memory Size\")\n",
    "\n",
    "if avg_acc_by_cores is not None:\n",
    "    create_accuracy_plot(axes[2], avg_acc_by_cores, \"cores\", \"Accuracy vs Number of Cores\")\n",
    "else:\n",
    "    axes[2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"plots/accuracy.png\", dpi=600, bbox_inches=\"tight\", format=\"png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, clearly a stupid test. The accuracy obviously won't increase or decrease depending on the experiment parameters - it's constantly 50%. That is, on average, there's no way to predict the outcome based on the features, in general.\n",
    "\n",
    "Other parameters will clearly affect the prediction accuracy, such as features used, which leagues to focus on, size of training data, etc.\n",
    "\n",
    "However, the focus of the course is to make computational experiments, not make accurate predictions. So we will leave it here.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
