{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Data Computational Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import SPARK_MASTER\n",
    "from data_loader import load_parquet_data\n",
    "from prepare_train_evaluate import train_and_evaluate\n",
    "from spark_session import create_spark_session\n",
    "from model_types import ModelConfig\n",
    "from experiment_types import ExperimentConfig, ExperimentResult, ExperimentSeriesConfig\n",
    "\n",
    "\n",
    "config = ExperimentSeriesConfig(\n",
    "    cores=[1, 2, 3, 4, 6, 8],\n",
    "    executor_memory_sizes=[\"1g\", \"2g\", \"4g\", \"6g\", \"10g\", \"16g\"],\n",
    "    driver_memory_sizes=[\"1g\", \"2g\", \"4g\", \"6g\", \"10g\", \"16g\"],\n",
    "    instances=([1, 2, 3, 4, 5, 6, 7, 8] if SPARK_MASTER != \"local[*]\" else [1]),\n",
    "    model_configs=[ModelConfig(\"logistic\"), ModelConfig(\"gbt\")],\n",
    "    train_size=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "def run_single_experiment(config: ExperimentConfig) -> ExperimentResult:\n",
    "    spark = create_spark_session(\n",
    "        force=True,\n",
    "        cores=config.cores,\n",
    "        driver_memory=config.driver_memory_size,\n",
    "        executor_memory=config.executor_memory_size,\n",
    "        instances=config.instances,\n",
    "    )\n",
    "\n",
    "    df, _ = load_parquet_data(spark)\n",
    "    df = df.cache()\n",
    "    df.count()  # Force caching\n",
    "\n",
    "    try:\n",
    "        metrics, df = train_and_evaluate(\n",
    "            df, config.model_config, test_size=config.test_size, train_size=config.train_size\n",
    "        )\n",
    "        spark.stop()\n",
    "\n",
    "        return ExperimentResult(\n",
    "            config,\n",
    "            metrics,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        spark.stop()\n",
    "        print(f\"Failed experiment with {config.as_pretty_string()}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "results: list[ExperimentResult] = []\n",
    "experiments: list[ExperimentConfig] = config.generate_experiment_configs()\n",
    "for index, config in enumerate(experiments):\n",
    "    result = run_single_experiment(config)\n",
    "    print(f\"Experiment {index + 1} of {len(experiments)}: {result.as_pretty_string()}\")\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_loader import write_experiment_results\n",
    "\n",
    "results_df = pd.DataFrame([r.as_pretty_dict() for r in results])\n",
    "\n",
    "write_experiment_results(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
